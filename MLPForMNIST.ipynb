{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDo/ziO8564CYJtDqogtll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuanAII/MLPforMNIST_classification/blob/main/MLPForMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "4LfQrCeYq5Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using MLP for MNIST Classification"
      ],
      "metadata": {
        "id": "3ODXQ-Fsq9H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torchvision import datasets , transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "vh0WdZBeq9KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) # convert PIL IMAGE -> tensor [0 , 1]\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "id": "2gjPl0pmq9Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_numpy(dataset):\n",
        "  X , y = [], []\n",
        "  for img , label in dataset:\n",
        "    X.append(img.view(-1).numpy())\n",
        "    y.append(label)\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "X_train , y_train = to_numpy(train_data)\n",
        "X_test  , y_test = to_numpy(test_data)"
      ],
      "metadata": {
        "id": "jEzbQv6wq9Q4"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Activation + Loss**"
      ],
      "metadata": {
        "id": "hhjMWJWtq9aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu (x):\n",
        "  return np.maximum(0 , x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "  return ( x > 0).astype(float)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "def cross_entropy(y_pred , y):\n",
        "  m = y.shape[0]\n",
        "  log_likelihood = -np.log(y_pred[range(m), y] + 1e-9)\n",
        "  return np.sum(log_likelihood)/m"
      ],
      "metadata": {
        "id": "nWuWC6l9xXSQ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MLP Class  ( 1 hidden layer )**"
      ],
      "metadata": {
        "id": "ueNU_4792-kM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NKy3sh3PxB4P"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP :\n",
        "  # Define MLP layer\n",
        "  def __init__(self , input_size , hidden_size , output_size) :\n",
        "    self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2. / input_size)\n",
        "    self.b1 = np.zeros((1, hidden_size))\n",
        "\n",
        "    self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2. / hidden_size)\n",
        "    self.b2 = np.zeros((1, output_size))\n",
        "\n",
        "  # Define forward\n",
        "  def forward(self , X) : # [batchsize , inputsize]\n",
        "    self.Z1 = X @ self.W1 + self.b1  # [batchsize , inputsize] * [input_size, hidden_size] = [batchsize , hidden_size]\n",
        "    self.A1 = relu(self.Z1)\n",
        "    self.Z2 = self.Z1 @ self.W2 + self.b2 #[batchsize , hidden_size] * [hidden_size , output_size ] = [batchsize , outputsize ]\n",
        "\n",
        "    self.A2 = softmax(self.Z2)\n",
        "\n",
        "    return self.A2 #[batchsize , outputsize ]\n",
        "\n",
        "  def backward(self, X, y_true, learning_rate):\n",
        "      m = X.shape[0]\n",
        "      y_one_hot = np.zeros_like(self.A2)\n",
        "      y_one_hot[np.arange(m), y_true] = 1\n",
        "\n",
        "      dZ2 = self.A2 - y_one_hot\n",
        "      dW2 = self.A1.T @ dZ2 / m\n",
        "      db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "      dA1 = dZ2 @ self.W2.T\n",
        "      dZ1 = dA1 * relu_derivative(self.Z1)\n",
        "      dW1 = X.T @ dZ1 / m\n",
        "      db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "\n",
        "      self.W1 -= learning_rate * dW1\n",
        "      self.b1 -= learning_rate * db1\n",
        "      self.W2 -= learning_rate * dW2\n",
        "      self.b2 -= learning_rate * db2\n",
        "\n",
        "  def predict(self, X):\n",
        "      probs = self.forward(X)\n",
        "      return np.argmax(probs, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "iUi_tO0DxB60"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kKKQ0NvRxB9c"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train MLP**"
      ],
      "metadata": {
        "id": "KQp-8FRCGGna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mlp():\n",
        "    model = MLP(input_size=784, hidden_size=128, output_size=10)\n",
        "\n",
        "    epochs = 30\n",
        "    batch_size = 64\n",
        "    learning_rate = 0.01\n",
        "\n",
        "    train_acc_list = []\n",
        "    test_acc_list = []\n",
        "\n",
        "\n",
        "    best_acc = 0\n",
        "    best_epoch = 0\n",
        "    best_train_acc = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Shuffle\n",
        "        permutation = np.random.permutation(X_train.shape[0])\n",
        "        X_train_shuffled = X_train[permutation]\n",
        "        y_train_shuffled = y_train[permutation]\n",
        "\n",
        "        for i in range(0, X_train.shape[0], batch_size):\n",
        "            X_batch = X_train_shuffled[i:i+batch_size]\n",
        "            y_batch = y_train_shuffled[i:i+batch_size]\n",
        "\n",
        "            y_pred = model.forward(X_batch)\n",
        "            loss = cross_entropy(y_pred, y_batch)\n",
        "            model.backward(X_batch, y_batch, learning_rate)\n",
        "\n",
        "        # Accuracy\n",
        "        y_pred_train = model.predict(X_train)\n",
        "        train_acc = np.mean(y_pred_train == y_train)\n",
        "        train_acc_list.append(train_acc)\n",
        "\n",
        "        y_pred_test = model.predict(X_test)\n",
        "        test_acc = np.mean(y_pred_test == y_test)\n",
        "        test_acc_list.append(test_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1:2d} - LR: {learning_rate:.5f} - Train Acc: {train_acc:.4f} - Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_train_acc = train_acc\n",
        "            best_epoch = epoch + 1\n",
        "            best_model = model\n",
        "\n",
        "    # Vẽ biểu đồ\n",
        "    plt.plot(range(1, epochs+1), train_acc_list, label='Train Accuracy')\n",
        "    plt.plot(range(1, epochs+1), test_acc_list, label='Test Accuracy')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Training vs Testing Accuracy (with LR)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    print(f\"\\n Best Epoch: {best_epoch}\")\n",
        "    print(f\" Best Train Accuracy: {best_train_acc:.4f}\")\n",
        "    print(f\" Best Test Accuracy:  {best_acc:.4f}\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "train_mlp()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "0WCDbUU5q9jl",
        "outputId": "4267e5b8-1099-4cff-ec0b-4f499e478307"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 - LR: 0.01000 - Train Acc: 0.8923 - Test Acc: 0.8984\n",
            "Epoch  2 - LR: 0.01000 - Train Acc: 0.9050 - Test Acc: 0.9057\n",
            "Epoch  3 - LR: 0.01000 - Train Acc: 0.9099 - Test Acc: 0.9103\n",
            "Epoch  4 - LR: 0.01000 - Train Acc: 0.9127 - Test Acc: 0.9127\n",
            "Epoch  5 - LR: 0.01000 - Train Acc: 0.9069 - Test Acc: 0.9062\n",
            "Epoch  6 - LR: 0.01000 - Train Acc: 0.8751 - Test Acc: 0.8735\n",
            "Epoch  7 - LR: 0.01000 - Train Acc: 0.8644 - Test Acc: 0.8642\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-85-3755112362.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_model\u001b[0m  \u001b[0;31m# có thể dùng để lưu/save tiếp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mtrain_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-85-3755112362.py\u001b[0m in \u001b[0;36mtrain_mlp\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_shuffled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-84-3875980954.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m# [batchsize , inputsize]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb1\u001b[0m  \u001b[0;31m# [batchsize , inputsize] * [input_size, hidden_size] = [batchsize , hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ1\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m \u001b[0;31m#[batchsize , hidden_size] * [hidden_size , output_size ] = [batchsize , outputsize ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-83-1980802087.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mrelu\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrelu_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}